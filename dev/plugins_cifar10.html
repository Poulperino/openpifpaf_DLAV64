
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Cifar10 &#8212; OpenPifPaf Guide DEV</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystyle.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="_static/favicon.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modules" href="moduledocs.html" />
    <link rel="prev" title="OpenCV" href="tutorial_opencv.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">OpenPifPaf Guide DEV</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="predict_cli.html">
   Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="examples.html">
   Examples
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="predict_api.html">
   Prediction API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="compute.html">
   Compute
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models.html">
   Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="datasets.html">
   Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="train.html">
   Training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cli_help.html">
   Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_overview.html">
   Plugins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="faq.html">
   FAQ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_custom.html">
   Custom Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_animalpose.html">
   Animal Keypoints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_wholebody.html">
   WholeBody
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_apollocar3d.html">
   Car Keypoints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_crowdpose.html">
   CrowdPose
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plugins_nuscenes.html">
   NuScenes 2D detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tutorial_opencv.html">
   OpenCV
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Cifar10
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="moduledocs.html">
   Modules
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   Bibliography
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Development
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="dev.html">
   Contribute
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="performance.html">
   Performance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/vita-epfl/openpifpaf">
   GitHub
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            This is the dev version of the Guide. Here is the <a href="https://vita-epfl.github.io/openpifpaf">stable version</a>.
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/vita-epfl/openpifpaf/main?urlpath=tree/guide/plugins_cifar10.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/vita-epfl/openpifpaf"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/vita-epfl/openpifpaf/issues/new?title=Issue%20on%20page%20%2Fplugins_cifar10.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/plugins_cifar10.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> On this page
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training">
   Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plot-training-logs">
   Plot Training Logs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction">
   Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation">
   Evaluation
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Cifar10</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> On this page </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training">
   Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plot-training-logs">
   Plot Training Logs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction">
   Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation">
   Evaluation
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="cifar10">
<h1>Cifar10<a class="headerlink" href="#cifar10" title="Permalink to this headline">#</a></h1>
<p>This page gives a quick introduction to OpenPifPaf’s Cifar10 plugin that is part of <code class="docutils literal notranslate"><span class="pre">openpifpaf.plugins</span></code>.
It demonstrates the plugin architecture.
There already is a nice dataset for CIFAR10 in <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> and a related <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">PyTorch tutorial</a>.
The plugin adds a <code class="docutils literal notranslate"><span class="pre">DataModule</span></code> that uses this dataset.
Let’s start with them setup for this notebook and registering all available OpenPifPaf plugins:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">openpifpaf</span><span class="o">.</span><span class="n">plugin</span><span class="o">.</span><span class="n">REGISTERED</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;openpifpaf.plugins.animalpose&#39;, &#39;openpifpaf.plugins.apollocar3d&#39;, &#39;openpifpaf.plugins.cifar10&#39;, &#39;openpifpaf.plugins.coco&#39;, &#39;openpifpaf.plugins.crowdpose&#39;, &#39;openpifpaf.plugins.nuscenes&#39;, &#39;openpifpaf.plugins.posetrack&#39;, &#39;openpifpaf.plugins.wholebody&#39;])
</pre></div>
</div>
</div>
</div>
<p>Next, we configure and instantiate the Cifar10 datamodule and look at the configured head metas:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># configure </span>
<span class="n">openpifpaf</span><span class="o">.</span><span class="n">plugins</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">Cifar10</span><span class="o">.</span><span class="n">debug</span> <span class="o">=</span> <span class="kc">True</span> 
<span class="n">openpifpaf</span><span class="o">.</span><span class="n">plugins</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">Cifar10</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># instantiate and inspect</span>
<span class="n">datamodule</span> <span class="o">=</span> <span class="n">openpifpaf</span><span class="o">.</span><span class="n">plugins</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">Cifar10</span><span class="p">()</span>
<span class="n">datamodule</span><span class="o">.</span><span class="n">set_loader_workers</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># no multi-processing to see debug outputs in main thread</span>
<span class="n">datamodule</span><span class="o">.</span><span class="n">head_metas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[CifDet(name=&#39;cifdet&#39;, dataset=&#39;cifar10&#39;, head_index=None, base_stride=None, upsample_stride=1, categories=(&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;), training_weights=None)]
</pre></div>
</div>
</div>
</div>
<p>We see here that CIFAR10 is being treated as a detection dataset (<code class="docutils literal notranslate"><span class="pre">CifDet</span></code>) and has 10 categories.
To create a network, we use the <code class="docutils literal notranslate"><span class="pre">factory()</span></code> function that takes the name of the base network <code class="docutils literal notranslate"><span class="pre">cifar10net</span></code> and the list of head metas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">openpifpaf</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">Factory</span><span class="p">(</span><span class="n">base_name</span><span class="o">=</span><span class="s1">&#39;cifar10net&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">factory</span><span class="p">(</span><span class="n">head_metas</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">head_metas</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can inspect the training data that is returned from <code class="docutils literal notranslate"><span class="pre">datamodule.train_loader()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># configure visualization</span>
<span class="n">openpifpaf</span><span class="o">.</span><span class="n">visualizer</span><span class="o">.</span><span class="n">Base</span><span class="o">.</span><span class="n">set_all_indices</span><span class="p">([</span><span class="s1">&#39;cifdet:9:regression&#39;</span><span class="p">])</span>  <span class="c1"># category 9 = truck</span>

<span class="c1"># Create a wrapper for a data loader that iterates over a set of matplotlib axes.</span>
<span class="c1"># The only purpose is to set a different matplotlib axis before each call to </span>
<span class="c1"># retrieve the next image from the data_loader so that it produces multiple</span>
<span class="c1"># debug images in one canvas side-by-side.</span>
<span class="k">def</span> <span class="nf">loop_over_axes</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
    <span class="n">previous_common_ax</span> <span class="o">=</span> <span class="n">openpifpaf</span><span class="o">.</span><span class="n">visualizer</span><span class="o">.</span><span class="n">Base</span><span class="o">.</span><span class="n">common_ax</span>
    <span class="n">train_loader_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">openpifpaf</span><span class="o">.</span><span class="n">visualizer</span><span class="o">.</span><span class="n">Base</span><span class="o">.</span><span class="n">common_ax</span> <span class="o">=</span> <span class="n">ax</span>
        <span class="k">yield</span> <span class="nb">next</span><span class="p">(</span><span class="n">train_loader_iter</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">openpifpaf</span><span class="o">.</span><span class="n">visualizer</span><span class="o">.</span><span class="n">Base</span><span class="o">.</span><span class="n">common_ax</span> <span class="o">=</span> <span class="n">previous_common_ax</span>

<span class="c1"># create a canvas and loop over the first few entries in the training data</span>
<span class="k">with</span> <span class="n">openpifpaf</span><span class="o">.</span><span class="n">show</span><span class="o">.</span><span class="n">canvas</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span> <span class="k">as</span> <span class="n">axs</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">meta</span> <span class="ow">in</span> <span class="n">loop_over_axes</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">train_loader</span><span class="p">()):</span>
        <span class="k">pass</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/plugins_cifar10_8_0.png" src="_images/plugins_cifar10_8_0.png" />
</div>
</div>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">#</a></h2>
<p>We train a very small network, <code class="docutils literal notranslate"><span class="pre">cifar10net</span></code>, for only one epoch. Afterwards, we will investigate its predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
python -m openpifpaf.train \
  --dataset=cifar10 --basenet=cifar10net --log-interval=50 \
  --epochs=3 --lr=0.0003 --momentum=0.95 --batch-size=16 \
  --lr-warm-up-epochs=0.1 --lr-decay 2.0 2.5 --lr-decay-epochs=0.1 \
  --loader-workers=2 --output=cifar10_tutorial.pkl
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:__main__:neural network device: cpu (CUDA available: False, count: 0)
INFO:openpifpaf.network.basenetworks:cifar10net: stride = 16, output features = 128
INFO:openpifpaf.network.losses.multi_head:multihead loss: [&#39;cifar10.cifdet.c&#39;, &#39;cifar10.cifdet.vec&#39;, &#39;cifar10.cifdet.scales&#39;], [1.0, 1.0, 1.0]
INFO:openpifpaf.logger:{&#39;type&#39;: &#39;process&#39;, &#39;argv&#39;: [&#39;/opt/hostedtoolcache/Python/3.8.16/x64/lib/python3.8/site-packages/openpifpaf/train.py&#39;, &#39;--dataset=cifar10&#39;, &#39;--basenet=cifar10net&#39;, &#39;--log-interval=50&#39;, &#39;--epochs=3&#39;, &#39;--lr=0.0003&#39;, &#39;--momentum=0.95&#39;, &#39;--batch-size=16&#39;, &#39;--lr-warm-up-epochs=0.1&#39;, &#39;--lr-decay&#39;, &#39;2.0&#39;, &#39;2.5&#39;, &#39;--lr-decay-epochs=0.1&#39;, &#39;--loader-workers=2&#39;, &#39;--output=cifar10_tutorial.pkl&#39;], &#39;args&#39;: {&#39;output&#39;: &#39;cifar10_tutorial.pkl&#39;, &#39;disable_cuda&#39;: False, &#39;ddp&#39;: False, &#39;local_rank&#39;: None, &#39;sync_batchnorm&#39;: True, &#39;resume_training&#39;: None, &#39;quiet&#39;: False, &#39;debug&#39;: False, &#39;log_stats&#39;: False, &#39;resnet_pretrained&#39;: True, &#39;resnet_pool0_stride&#39;: 0, &#39;resnet_input_conv_stride&#39;: 2, &#39;resnet_input_conv2_stride&#39;: 0, &#39;resnet_block5_dilation&#39;: 1, &#39;resnet_remove_last_block&#39;: False, &#39;shufflenetv2_pretrained&#39;: True, &#39;xcit_out_channels&#39;: None, &#39;xcit_out_maxpool&#39;: False, &#39;xcit_pretrained&#39;: True, &#39;swin_drop_path_rate&#39;: 0.2, &#39;swin_input_upsample&#39;: False, &#39;swin_use_fpn&#39;: False, &#39;swin_fpn_out_channels&#39;: None, &#39;swin_fpn_level&#39;: 3, &#39;swin_pretrained&#39;: True, &#39;mobilenetv2_pretrained&#39;: True, &#39;squeezenet_pretrained&#39;: True, &#39;shufflenetv2k_input_conv2_stride&#39;: 0, &#39;shufflenetv2k_input_conv2_outchannels&#39;: None, &#39;shufflenetv2k_stage4_dilation&#39;: 1, &#39;shufflenetv2k_kernel&#39;: 5, &#39;shufflenetv2k_conv5_as_stage&#39;: False, &#39;shufflenetv2k_instance_norm&#39;: False, &#39;shufflenetv2k_group_norm&#39;: False, &#39;shufflenetv2k_leaky_relu&#39;: False, &#39;mobilenetv3_pretrained&#39;: True, &#39;cf4_dropout&#39;: 0.0, &#39;cf4_inplace_ops&#39;: True, &#39;checkpoint&#39;: None, &#39;basenet&#39;: &#39;cifar10net&#39;, &#39;cross_talk&#39;: 0.0, &#39;download_progress&#39;: True, &#39;head_consolidation&#39;: &#39;filter_and_extend&#39;, &#39;lambdas&#39;: None, &#39;component_lambdas&#39;: None, &#39;auto_tune_mtl&#39;: False, &#39;auto_tune_mtl_variance&#39;: False, &#39;task_sparsity_weight&#39;: 0.0, &#39;soft_clamp&#39;: 5.0, &#39;loss_prescale&#39;: 1.0, &#39;regression_loss&#39;: &#39;laplace&#39;, &#39;bce_total_soft_clamp&#39;: None, &#39;r_smooth&#39;: 0.0, &#39;b_scale&#39;: 1.0, &#39;scale_log&#39;: False, &#39;scale_soft_clamp&#39;: 5.0, &#39;background_weight&#39;: 1.0, &#39;focal_alpha&#39;: 0.5, &#39;focal_gamma&#39;: 1.0, &#39;focal_detach&#39;: False, &#39;focal_clamp&#39;: True, &#39;bce_min&#39;: 0.0, &#39;bce_soft_clamp&#39;: 5.0, &#39;bce_background_clamp&#39;: -15.0, &#39;laplace_soft_clamp&#39;: 5.0, &#39;epochs&#39;: 3, &#39;train_batches&#39;: None, &#39;val_batches&#39;: None, &#39;clip_grad_norm&#39;: 0.0, &#39;clip_grad_value&#39;: 0.0, &#39;log_interval&#39;: 50, &#39;val_interval&#39;: 1, &#39;stride_apply&#39;: 1, &#39;fix_batch_norm&#39;: False, &#39;ema&#39;: 0.01, &#39;profile&#39;: None, &#39;cif_side_length&#39;: 4, &#39;caf_min_size&#39;: 3, &#39;caf_fixed_size&#39;: False, &#39;caf_aspect_ratio&#39;: 0.0, &#39;encoder_suppress_selfhidden&#39;: True, &#39;encoder_suppress_invisible&#39;: False, &#39;encoder_suppress_collision&#39;: False, &#39;momentum&#39;: 0.95, &#39;beta2&#39;: 0.999, &#39;adam_eps&#39;: 1e-06, &#39;nesterov&#39;: True, &#39;weight_decay&#39;: 0.0, &#39;adam&#39;: False, &#39;adamw&#39;: False, &#39;amsgrad&#39;: False, &#39;lr&#39;: 0.0003, &#39;lr_decay&#39;: [2.0, 2.5], &#39;lr_decay_factor&#39;: 0.1, &#39;lr_decay_epochs&#39;: 0.1, &#39;lr_warm_up_start_epoch&#39;: 0, &#39;lr_warm_up_epochs&#39;: 0.1, &#39;lr_warm_up_factor&#39;: 0.001, &#39;lr_warm_restarts&#39;: [], &#39;lr_warm_restart_duration&#39;: 0.5, &#39;dataset&#39;: &#39;cifar10&#39;, &#39;loader_workers&#39;: 2, &#39;batch_size&#39;: 16, &#39;dataset_weights&#39;: None, &#39;animal_train_annotations&#39;: &#39;data-animalpose/annotations/animal_keypoints_20_train.json&#39;, &#39;animal_val_annotations&#39;: &#39;data-animalpose/annotations/animal_keypoints_20_val.json&#39;, &#39;animal_train_image_dir&#39;: &#39;data-animalpose/images/train/&#39;, &#39;animal_val_image_dir&#39;: &#39;data-animalpose/images/val/&#39;, &#39;animal_square_edge&#39;: 513, &#39;animal_extended_scale&#39;: False, &#39;animal_orientation_invariant&#39;: 0.0, &#39;animal_blur&#39;: 0.0, &#39;animal_augmentation&#39;: True, &#39;animal_rescale_images&#39;: 1.0, &#39;animal_upsample&#39;: 1, &#39;animal_min_kp_anns&#39;: 1, &#39;animal_bmin&#39;: 1, &#39;animal_eval_test2017&#39;: False, &#39;animal_eval_testdev2017&#39;: False, &#39;animal_eval_annotation_filter&#39;: True, &#39;animal_eval_long_edge&#39;: 0, &#39;animal_eval_extended_scale&#39;: False, &#39;animal_eval_orientation_invariant&#39;: 0.0, &#39;apollo_train_annotations&#39;: &#39;data-apollocar3d/annotations/apollo_keypoints_66_train.json&#39;, &#39;apollo_val_annotations&#39;: &#39;data-apollocar3d/annotations/apollo_keypoints_66_val.json&#39;, &#39;apollo_train_image_dir&#39;: &#39;data-apollocar3d/images/train/&#39;, &#39;apollo_val_image_dir&#39;: &#39;data-apollocar3d/images/val/&#39;, &#39;apollo_square_edge&#39;: 513, &#39;apollo_extended_scale&#39;: False, &#39;apollo_orientation_invariant&#39;: 0.0, &#39;apollo_blur&#39;: 0.0, &#39;apollo_augmentation&#39;: True, &#39;apollo_rescale_images&#39;: 1.0, &#39;apollo_upsample&#39;: 1, &#39;apollo_min_kp_anns&#39;: 1, &#39;apollo_bmin&#39;: 1, &#39;apollo_apply_local_centrality&#39;: False, &#39;apollo_eval_annotation_filter&#39;: True, &#39;apollo_eval_long_edge&#39;: 0, &#39;apollo_eval_extended_scale&#39;: False, &#39;apollo_eval_orientation_invariant&#39;: 0.0, &#39;apollo_use_24_kps&#39;: False, &#39;cifar10_root_dir&#39;: &#39;data-cifar10/&#39;, &#39;cifar10_download&#39;: False, &#39;cocodet_train_annotations&#39;: &#39;data-mscoco/annotations/instances_train2017.json&#39;, &#39;cocodet_val_annotations&#39;: &#39;data-mscoco/annotations/instances_val2017.json&#39;, &#39;cocodet_train_image_dir&#39;: &#39;data-mscoco/images/train2017/&#39;, &#39;cocodet_val_image_dir&#39;: &#39;data-mscoco/images/val2017/&#39;, &#39;cocodet_square_edge&#39;: 513, &#39;cocodet_extended_scale&#39;: False, &#39;cocodet_orientation_invariant&#39;: 0.0, &#39;cocodet_blur&#39;: 0.0, &#39;cocodet_augmentation&#39;: True, &#39;cocodet_rescale_images&#39;: 1.0, &#39;cocodet_upsample&#39;: 1, &#39;cocokp_train_annotations&#39;: &#39;data-mscoco/annotations/person_keypoints_train2017.json&#39;, &#39;cocokp_val_annotations&#39;: &#39;data-mscoco/annotations/person_keypoints_val2017.json&#39;, &#39;cocokp_train_image_dir&#39;: &#39;data-mscoco/images/train2017/&#39;, &#39;cocokp_val_image_dir&#39;: &#39;data-mscoco/images/val2017/&#39;, &#39;cocokp_square_edge&#39;: 385, &#39;cocokp_with_dense&#39;: False, &#39;cocokp_extended_scale&#39;: False, &#39;cocokp_orientation_invariant&#39;: 0.0, &#39;cocokp_blur&#39;: 0.0, &#39;cocokp_augmentation&#39;: True, &#39;cocokp_rescale_images&#39;: 1.0, &#39;cocokp_upsample&#39;: 1, &#39;cocokp_min_kp_anns&#39;: 1, &#39;cocokp_bmin&#39;: 0.1, &#39;cocokp_eval_test2017&#39;: False, &#39;cocokp_eval_testdev2017&#39;: False, &#39;coco_eval_annotation_filter&#39;: True, &#39;coco_eval_long_edge&#39;: 641, &#39;coco_eval_extended_scale&#39;: False, &#39;coco_eval_orientation_invariant&#39;: 0.0, &#39;crowdpose_train_annotations&#39;: &#39;data-crowdpose/json/crowdpose_train.json&#39;, &#39;crowdpose_val_annotations&#39;: &#39;data-crowdpose/json/crowdpose_val.json&#39;, &#39;crowdpose_image_dir&#39;: &#39;data-crowdpose/images/&#39;, &#39;crowdpose_square_edge&#39;: 385, &#39;crowdpose_extended_scale&#39;: False, &#39;crowdpose_orientation_invariant&#39;: 0.0, &#39;crowdpose_augmentation&#39;: True, &#39;crowdpose_rescale_images&#39;: 1.0, &#39;crowdpose_upsample&#39;: 1, &#39;crowdpose_min_kp_anns&#39;: 1, &#39;crowdpose_eval_test&#39;: False, &#39;crowdpose_eval_long_edge&#39;: 641, &#39;crowdpose_eval_extended_scale&#39;: False, &#39;crowdpose_eval_orientation_invariant&#39;: 0.0, &#39;crowdpose_index&#39;: None, &#39;nuscenes_train_annotations&#39;: &#39;../../../NuScenes/mscoco_style_annotations/nuimages_v1.0-train.json&#39;, &#39;nuscenes_val_annotations&#39;: &#39;../../../NuScenes/mscoco_style_annotations/nuimages_v1.0-val.json&#39;, &#39;nuscenes_train_image_dir&#39;: &#39;../../../NuScenes/nuimages-v1.0-all-samples&#39;, &#39;nuscenes_val_image_dir&#39;: &#39;../../../NuScenes/nuimages-v1.0-all-samples&#39;, &#39;nuscenes_square_edge&#39;: 513, &#39;nuscenes_extended_scale&#39;: False, &#39;nuscenes_orientation_invariant&#39;: 0.0, &#39;nuscenes_blur&#39;: 0.0, &#39;nuscenes_augmentation&#39;: True, &#39;nuscenes_rescale_images&#39;: 1.0, &#39;nuscenes_upsample&#39;: 1, &#39;posetrack2018_train_annotations&#39;: &#39;data-posetrack2018/annotations/train/*.json&#39;, &#39;posetrack2018_val_annotations&#39;: &#39;data-posetrack2018/annotations/val/*.json&#39;, &#39;posetrack2018_eval_annotations&#39;: &#39;data-posetrack2018/annotations/val/*.json&#39;, &#39;posetrack2018_data_root&#39;: &#39;data-posetrack2018&#39;, &#39;posetrack_square_edge&#39;: 385, &#39;posetrack_with_dense&#39;: False, &#39;posetrack_augmentation&#39;: True, &#39;posetrack_rescale_images&#39;: 1.0, &#39;posetrack_upsample&#39;: 1, &#39;posetrack_min_kp_anns&#39;: 1, &#39;posetrack_bmin&#39;: 0.1, &#39;posetrack_sample_pairing&#39;: 0.0, &#39;posetrack_image_augmentations&#39;: 0.0, &#39;posetrack_max_shift&#39;: 30.0, &#39;posetrack_eval_long_edge&#39;: 801, &#39;posetrack_eval_extended_scale&#39;: False, &#39;posetrack_eval_orientation_invariant&#39;: 0.0, &#39;posetrack_ablation_without_tcaf&#39;: False, &#39;posetrack2017_eval_annotations&#39;: &#39;data-posetrack2017/annotations/val/*.json&#39;, &#39;posetrack2017_data_root&#39;: &#39;data-posetrack2017&#39;, &#39;cocokpst_max_shift&#39;: 30.0, &#39;wholebody_train_annotations&#39;: &#39;data-mscoco/annotations/person_keypoints_train2017_wholebody_pifpaf_style.json&#39;, &#39;wholebody_val_annotations&#39;: &#39;data-mscoco/annotations/coco_wholebody_val_v1.0.json&#39;, &#39;wholebody_train_image_dir&#39;: &#39;data-mscoco/images/train2017/&#39;, &#39;wholebody_val_image_dir&#39;: &#39;data-mscoco/images/val2017&#39;, &#39;wholebody_square_edge&#39;: 385, &#39;wholebody_extended_scale&#39;: False, &#39;wholebody_orientation_invariant&#39;: 0.0, &#39;wholebody_blur&#39;: 0.0, &#39;wholebody_augmentation&#39;: True, &#39;wholebody_rescale_images&#39;: 1.0, &#39;wholebody_upsample&#39;: 1, &#39;wholebody_min_kp_anns&#39;: 1, &#39;wholebody_bmin&#39;: 1.0, &#39;wholebody_apply_local_centrality&#39;: False, &#39;wholebody_eval_test2017&#39;: False, &#39;wholebody_eval_testdev2017&#39;: False, &#39;wholebody_eval_annotation_filter&#39;: True, &#39;wholebody_eval_long_edge&#39;: 641, &#39;wholebody_eval_extended_scale&#39;: False, &#39;wholebody_eval_orientation_invariant&#39;: 0.0, &#39;save_all&#39;: None, &#39;show&#39;: False, &#39;image_width&#39;: None, &#39;image_height&#39;: None, &#39;image_dpi_factor&#39;: 2.0, &#39;image_min_dpi&#39;: 50.0, &#39;show_file_extension&#39;: &#39;jpeg&#39;, &#39;textbox_alpha&#39;: 0.5, &#39;text_color&#39;: &#39;white&#39;, &#39;font_size&#39;: 8, &#39;monocolor_connections&#39;: False, &#39;line_width&#39;: None, &#39;skeleton_solid_threshold&#39;: 0.5, &#39;show_box&#39;: False, &#39;white_overlay&#39;: False, &#39;show_joint_scales&#39;: False, &#39;show_joint_confidences&#39;: False, &#39;show_decoding_order&#39;: False, &#39;show_frontier_order&#39;: False, &#39;show_only_decoded_connections&#39;: False, &#39;video_fps&#39;: 10, &#39;video_dpi&#39;: 100, &#39;debug_indices&#39;: [], &#39;device&#39;: device(type=&#39;cpu&#39;), &#39;pin_memory&#39;: False}, &#39;version&#39;: &#39;0.14.0+16.g5be8d6e&#39;, &#39;plugin_versions&#39;: {}, &#39;hostname&#39;: &#39;fv-az452-347&#39;}
INFO:openpifpaf.optimize:SGD optimizer
INFO:openpifpaf.optimize:training batches per epoch = 3125
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;config&#39;, &#39;field_names&#39;: [&#39;cifar10.cifdet.c&#39;, &#39;cifar10.cifdet.vec&#39;, &#39;cifar10.cifdet.scales&#39;]}
INFO:openpifpaf.network.trainer:model written: cifar10_tutorial.pkl.epoch000
INFO:openpifpaf.network.trainer:training state written: cifar10_tutorial.pkl.optim.epoch000
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 0, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.035, &#39;data_time&#39;: 0.069, &#39;lr&#39;: 3e-07, &#39;loss&#39;: 68.289, &#39;head_losses&#39;: [1.949, 66.34, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 50, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 9.1e-07, &#39;loss&#39;: 68.413, &#39;head_losses&#39;: [1.872, 66.541, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 2.74e-06, &#39;loss&#39;: 68.524, &#39;head_losses&#39;: [1.868, 66.656, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.018, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 8.26e-06, &#39;loss&#39;: 68.401, &#39;head_losses&#39;: [1.863, 66.538, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 2.495e-05, &#39;loss&#39;: 67.577, &#39;head_losses&#39;: [1.982, 65.595, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 7.536e-05, &#39;loss&#39;: 66.334, &#39;head_losses&#39;: [2.009, 64.324, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.00022757, &#39;loss&#39;: 55.444, &#39;head_losses&#39;: [7.288, 48.156, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.03, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: 26.925, &#39;head_losses&#39;: [-0.96, 27.885, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: 4.468, &#39;head_losses&#39;: [-6.288, 10.756, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -2.077, &#39;head_losses&#39;: [-7.655, 5.577, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -3.749, &#39;head_losses&#39;: [-8.501, 4.752, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -6.259, &#39;head_losses&#39;: [-8.857, 2.598, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -7.088, &#39;head_losses&#39;: [-8.227, 1.139, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -7.832, &#39;head_losses&#39;: [-9.005, 1.174, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -4.943, &#39;head_losses&#39;: [-9.363, 4.421, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.0, &#39;head_losses&#39;: [-9.256, 1.257, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.686, &#39;head_losses&#39;: [-9.075, 0.389, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -6.799, &#39;head_losses&#39;: [-9.257, 2.458, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.508, &#39;head_losses&#39;: [-9.138, 0.63, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.026, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -7.715, &#39;head_losses&#39;: [-9.228, 1.513, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.085, &#39;head_losses&#39;: [-9.294, 0.209, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -7.181, &#39;head_losses&#39;: [-9.396, 2.216, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.019, &#39;head_losses&#39;: [-9.31, 0.291, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.511, &#39;head_losses&#39;: [-9.336, 0.826, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.954, &#39;head_losses&#39;: [-9.212, 0.258, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.058, &#39;head_losses&#39;: [-9.226, 0.168, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.372, &#39;head_losses&#39;: [-9.176, 0.803, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -6.018, &#39;head_losses&#39;: [-9.487, 3.469, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.517, &#39;head_losses&#39;: [-9.593, 0.077, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.003, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -6.65, &#39;head_losses&#39;: [-9.498, 2.848, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.221, &#39;head_losses&#39;: [-9.474, 1.253, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.513, &#39;head_losses&#39;: [-9.676, 1.162, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.857, &#39;head_losses&#39;: [-9.374, 0.517, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.633, &#39;head_losses&#39;: [-9.604, 0.971, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.018, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.937, &#39;head_losses&#39;: [-9.506, 0.568, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.507, &#39;head_losses&#39;: [-9.998, 0.491, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.012, &#39;data_time&#39;: 0.009, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.864, &#39;head_losses&#39;: [-9.356, 0.493, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.964, &#39;head_losses&#39;: [-9.565, 0.601, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.989, &#39;head_losses&#39;: [-9.251, 0.262, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 1950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.592, &#39;head_losses&#39;: [-9.997, 1.405, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.787, &#39;head_losses&#39;: [-9.887, 0.1, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.281, &#39;head_losses&#39;: [-9.385, 0.104, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.315, &#39;head_losses&#39;: [-9.864, 0.549, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.016, &#39;data_time&#39;: 0.006, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.703, &#39;head_losses&#39;: [-9.545, 0.842, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.251, &#39;head_losses&#39;: [-9.712, 0.461, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.35, &#39;head_losses&#39;: [-9.218, 0.868, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.748, &#39;head_losses&#39;: [-9.953, 1.205, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.03, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.836, &#39;head_losses&#39;: [-9.945, 0.109, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.685, &#39;head_losses&#39;: [-9.751, 0.066, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.463, &#39;head_losses&#39;: [-9.923, 0.459, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -6.732, &#39;head_losses&#39;: [-10.091, 3.359, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.852, &#39;head_losses&#39;: [-9.954, 0.102, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.024, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.36, &#39;head_losses&#39;: [-9.637, 0.277, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.515, &#39;head_losses&#39;: [-9.881, 1.366, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.096, &#39;head_losses&#39;: [-10.194, 0.098, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.025, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.738, &#39;head_losses&#39;: [-10.107, 0.37, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.433, &#39;head_losses&#39;: [-9.977, 0.544, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.202, &#39;head_losses&#39;: [-9.638, 0.436, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.345, &#39;head_losses&#39;: [-9.919, 0.574, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 2950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.145, &#39;head_losses&#39;: [-10.183, 0.038, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 3000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.569, &#39;head_losses&#39;: [-9.619, 1.05, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 3050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.33, &#39;head_losses&#39;: [-9.498, 0.169, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 0, &#39;batch&#39;: 3100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.704, &#39;head_losses&#39;: [-9.986, 0.282, 0.0]}
INFO:openpifpaf.network.trainer:applying ema
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train-epoch&#39;, &#39;epoch&#39;: 1, &#39;loss&#39;: 0.12703, &#39;head_losses&#39;: [-8.09993, 8.22696, 0.0], &#39;time&#39;: 72.0, &#39;n_clipped_grad&#39;: 0, &#39;max_norm&#39;: 0.0}
INFO:openpifpaf.network.trainer:model written: cifar10_tutorial.pkl.epoch001
INFO:openpifpaf.network.trainer:training state written: cifar10_tutorial.pkl.optim.epoch001
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;val-epoch&#39;, &#39;epoch&#39;: 1, &#39;loss&#39;: -10.13213, &#39;head_losses&#39;: [-10.02996, -0.10217, 0.0], &#39;time&#39;: 12.0}
INFO:openpifpaf.network.trainer:restoring params from before ema
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 0, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.031, &#39;data_time&#39;: 0.056, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.946, &#39;head_losses&#39;: [-10.113, 0.167, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 50, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.026, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.931, &#39;head_losses&#39;: [-10.258, 0.327, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.97, &#39;head_losses&#39;: [-10.159, 0.188, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.005, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -4.162, &#39;head_losses&#39;: [-10.342, 6.181, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.622, &#39;head_losses&#39;: [-9.808, 0.186, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.633, &#39;head_losses&#39;: [-10.312, 0.679, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.645, &#39;head_losses&#39;: [-10.258, 0.613, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.742, &#39;head_losses&#39;: [-9.669, 0.927, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.24, &#39;head_losses&#39;: [-10.35, 0.11, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.027, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.821, &#39;head_losses&#39;: [-10.097, 0.276, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.404, &#39;head_losses&#39;: [-9.854, 0.451, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.808, &#39;head_losses&#39;: [-10.337, 0.529, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.026, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.705, &#39;head_losses&#39;: [-10.197, 1.493, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.003, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.554, &#39;head_losses&#39;: [-9.999, 1.444, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.03, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.704, &#39;head_losses&#39;: [-9.724, 1.02, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.789, &#39;head_losses&#39;: [-10.129, 0.341, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.425, &#39;head_losses&#39;: [-9.787, 1.362, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.939, &#39;head_losses&#39;: [-10.439, 0.5, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.092, &#39;head_losses&#39;: [-10.512, 0.42, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.018, &#39;head_losses&#39;: [-9.337, 0.319, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.958, &#39;head_losses&#39;: [-10.552, 0.595, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.018, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.974, &#39;head_losses&#39;: [-10.184, 0.21, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.089, &#39;head_losses&#39;: [-10.163, 0.074, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.003, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.862, &#39;head_losses&#39;: [-10.351, 0.489, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.026, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.746, &#39;head_losses&#39;: [-10.173, 1.428, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.534, &#39;head_losses&#39;: [-10.185, 1.65, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.884, &#39;head_losses&#39;: [-10.382, 0.497, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.41, &#39;head_losses&#39;: [-9.989, 0.579, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.375, &#39;head_losses&#39;: [-10.514, 0.14, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.106, &#39;head_losses&#39;: [-10.114, 0.008, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.187, &#39;head_losses&#39;: [-10.398, 0.211, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.545, &#39;head_losses&#39;: [-10.493, 0.949, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.713, &#39;head_losses&#39;: [-10.325, 0.611, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.115, &#39;head_losses&#39;: [-10.426, 0.311, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.775, &#39;head_losses&#39;: [-10.323, 0.549, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.026, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.106, &#39;head_losses&#39;: [-10.201, 0.095, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.017, &#39;data_time&#39;: 0.005, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.408, &#39;head_losses&#39;: [-9.57, 0.162, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.493, &#39;head_losses&#39;: [-9.895, 0.402, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.391, &#39;head_losses&#39;: [-10.517, 1.126, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 1950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.165, &#39;head_losses&#39;: [-9.407, 0.242, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.759, &#39;head_losses&#39;: [-10.323, 0.564, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.216, &#39;head_losses&#39;: [-10.49, 0.274, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.698, &#39;head_losses&#39;: [-10.714, 0.016, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.113, &#39;head_losses&#39;: [-10.423, 0.31, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.372, &#39;head_losses&#39;: [-10.559, 0.187, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -8.435, &#39;head_losses&#39;: [-9.718, 1.282, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.018, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.833, &#39;head_losses&#39;: [-10.086, 0.253, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.942, &#39;head_losses&#39;: [-10.166, 0.225, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.99, &#39;head_losses&#39;: [-10.157, 0.168, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.501, &#39;head_losses&#39;: [-10.637, 1.136, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.958, &#39;head_losses&#39;: [-10.337, 0.379, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.206, &#39;head_losses&#39;: [-10.244, 0.038, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.12, &#39;head_losses&#39;: [-10.223, 0.103, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.331, &#39;head_losses&#39;: [-10.607, 0.276, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.027, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.371, &#39;head_losses&#39;: [-10.473, 0.101, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.893, &#39;head_losses&#39;: [-10.281, 0.388, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.406, &#39;head_losses&#39;: [-11.118, 0.712, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.434, &#39;head_losses&#39;: [-10.458, 0.024, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.02, &#39;head_losses&#39;: [-10.256, 0.236, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 2950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.647, &#39;head_losses&#39;: [-10.316, 0.669, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 3000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.029, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.456, &#39;head_losses&#39;: [-10.495, 0.038, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 3050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -9.67, &#39;head_losses&#39;: [-10.565, 0.895, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 1, &#39;batch&#39;: 3100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.027, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.087, &#39;head_losses&#39;: [-10.356, 0.269, 0.0]}
INFO:openpifpaf.network.trainer:applying ema
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train-epoch&#39;, &#39;epoch&#39;: 2, &#39;loss&#39;: -9.76827, &#39;head_losses&#39;: [-10.23719, 0.46892, 0.0], &#39;time&#39;: 72.4, &#39;n_clipped_grad&#39;: 0, &#39;max_norm&#39;: 0.0}
INFO:openpifpaf.network.trainer:model written: cifar10_tutorial.pkl.epoch002
INFO:openpifpaf.network.trainer:training state written: cifar10_tutorial.pkl.optim.epoch002
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;val-epoch&#39;, &#39;epoch&#39;: 2, &#39;loss&#39;: -10.6708, &#39;head_losses&#39;: [-10.53713, -0.13367, 0.0], &#39;time&#39;: 12.3}
INFO:openpifpaf.network.trainer:restoring params from before ema
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 0, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.059, &#39;lr&#39;: 0.0003, &#39;loss&#39;: -10.309, &#39;head_losses&#39;: [-10.796, 0.488, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 50, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 0.00020755, &#39;loss&#39;: -10.062, &#39;head_losses&#39;: [-10.03, -0.032, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.005, &#39;lr&#39;: 0.00014359, &#39;loss&#39;: -10.948, &#39;head_losses&#39;: [-10.86, -0.088, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 9.934e-05, &#39;loss&#39;: -11.231, &#39;head_losses&#39;: [-11.155, -0.077, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 6.873e-05, &#39;loss&#39;: -10.716, &#39;head_losses&#39;: [-10.576, -0.14, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 4.755e-05, &#39;loss&#39;: -11.117, &#39;head_losses&#39;: [-10.979, -0.138, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.018, &#39;data_time&#39;: 0.004, &#39;lr&#39;: 3.289e-05, &#39;loss&#39;: -10.96, &#39;head_losses&#39;: [-10.814, -0.146, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.038, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.842, &#39;head_losses&#39;: [-10.698, -0.144, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.683, &#39;head_losses&#39;: [-10.63, -0.054, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.029, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.525, &#39;head_losses&#39;: [-10.402, -0.122, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.509, &#39;head_losses&#39;: [-10.339, -0.17, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.954, &#39;head_losses&#39;: [-10.794, -0.16, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.33, &#39;head_losses&#39;: [-10.175, -0.155, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.003, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.411, &#39;head_losses&#39;: [-10.264, -0.147, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.788, &#39;head_losses&#39;: [-10.621, -0.167, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.916, &#39;head_losses&#39;: [-10.739, -0.177, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.016, &#39;data_time&#39;: 0.006, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.873, &#39;head_losses&#39;: [-10.706, -0.167, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.846, &#39;head_losses&#39;: [-10.677, -0.169, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -11.524, &#39;head_losses&#39;: [-11.349, -0.176, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.679, &#39;head_losses&#39;: [-10.51, -0.169, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.729, &#39;head_losses&#39;: [-10.556, -0.173, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.812, &#39;head_losses&#39;: [-10.635, -0.177, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -11.192, &#39;head_losses&#39;: [-11.054, -0.138, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -11.294, &#39;head_losses&#39;: [-11.135, -0.16, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.783, &#39;head_losses&#39;: [-10.616, -0.167, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -11.077, &#39;head_losses&#39;: [-10.897, -0.181, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -11.049, &#39;head_losses&#39;: [-10.871, -0.178, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.839, &#39;head_losses&#39;: [-10.674, -0.165, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -11.089, &#39;head_losses&#39;: [-10.907, -0.181, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.015, &#39;data_time&#39;: 0.007, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.951, &#39;head_losses&#39;: [-10.773, -0.178, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.03, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.644, &#39;head_losses&#39;: [-10.458, -0.186, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-05, &#39;loss&#39;: -10.963, &#39;head_losses&#39;: [-10.777, -0.185, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.017, &#39;data_time&#39;: 0.005, &#39;lr&#39;: 2.276e-05, &#39;loss&#39;: -10.702, &#39;head_losses&#39;: [-10.547, -0.156, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 1.574e-05, &#39;loss&#39;: -10.851, &#39;head_losses&#39;: [-10.69, -0.161, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 1.089e-05, &#39;loss&#39;: -11.017, &#39;head_losses&#39;: [-10.837, -0.18, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.019, &#39;data_time&#39;: 0.003, &#39;lr&#39;: 7.54e-06, &#39;loss&#39;: -10.907, &#39;head_losses&#39;: [-10.723, -0.183, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 5.21e-06, &#39;loss&#39;: -10.409, &#39;head_losses&#39;: [-10.251, -0.159, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 3.61e-06, &#39;loss&#39;: -11.012, &#39;head_losses&#39;: [-10.825, -0.187, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.733, &#39;head_losses&#39;: [-10.558, -0.176, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 1950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.859, &#39;head_losses&#39;: [-10.665, -0.193, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.022, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.8, &#39;head_losses&#39;: [-10.621, -0.179, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.026, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.285, &#39;head_losses&#39;: [-10.093, -0.192, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.76, &#39;head_losses&#39;: [-10.562, -0.198, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2150, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.862, &#39;head_losses&#39;: [-10.669, -0.193, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2200, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.017, &#39;data_time&#39;: 0.005, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.814, &#39;head_losses&#39;: [-10.635, -0.179, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2250, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.026, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.598, &#39;head_losses&#39;: [-10.426, -0.172, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2300, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.974, &#39;head_losses&#39;: [-10.775, -0.198, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2350, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.001, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -11.034, &#39;head_losses&#39;: [-10.862, -0.172, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2400, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.006, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.454, &#39;head_losses&#39;: [-10.296, -0.158, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2450, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.881, &#39;head_losses&#39;: [-10.696, -0.185, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2500, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.779, &#39;head_losses&#39;: [-10.598, -0.181, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2550, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.885, &#39;head_losses&#39;: [-10.712, -0.173, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2600, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.233, &#39;head_losses&#39;: [-10.054, -0.18, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2650, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.627, &#39;head_losses&#39;: [-10.44, -0.187, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2700, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -11.112, &#39;head_losses&#39;: [-10.934, -0.178, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2750, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.752, &#39;head_losses&#39;: [-10.575, -0.176, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2800, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.794, &#39;head_losses&#39;: [-10.608, -0.186, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2850, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.717, &#39;head_losses&#39;: [-10.528, -0.189, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2900, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.738, &#39;head_losses&#39;: [-10.578, -0.16, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 2950, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.023, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.918, &#39;head_losses&#39;: [-10.739, -0.179, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 3000, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.924, &#39;head_losses&#39;: [-10.728, -0.196, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 3050, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.02, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.883, &#39;head_losses&#39;: [-10.688, -0.196, 0.0]}
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 3100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.63, &#39;head_losses&#39;: [-10.434, -0.196, 0.0]}
INFO:openpifpaf.network.trainer:applying ema
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;train-epoch&#39;, &#39;epoch&#39;: 3, &#39;loss&#39;: -10.7629, &#39;head_losses&#39;: [-10.60366, -0.15924, 0.0], &#39;time&#39;: 72.7, &#39;n_clipped_grad&#39;: 0, &#39;max_norm&#39;: 0.0}
INFO:openpifpaf.network.trainer:model written: cifar10_tutorial.pkl.epoch003
INFO:openpifpaf.network.trainer:training state written: cifar10_tutorial.pkl.optim.epoch003
INFO:openpifpaf.network.trainer:{&#39;type&#39;: &#39;val-epoch&#39;, &#39;epoch&#39;: 3, &#39;loss&#39;: -10.81007, &#39;head_losses&#39;: [-10.63083, -0.17924, 0.0], &#39;time&#39;: 12.5}
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-training-logs">
<h2>Plot Training Logs<a class="headerlink" href="#plot-training-logs" title="Permalink to this headline">#</a></h2>
<p>You can create a set of plots from the command line with <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">openpifpaf.logs</span> <span class="pre">cifar10_tutorial.pkl.log</span></code>. You can also overlay multiple runs. Below we call the plotting code from that command directly to show the output in this notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">openpifpaf</span><span class="o">.</span><span class="n">logs</span><span class="o">.</span><span class="n">Plots</span><span class="p">([</span><span class="s1">&#39;cifar10_tutorial.pkl.log&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">show_all</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;cifar10_tutorial.pkl.log&#39;: [&#39;--dataset=cifar10&#39;,
                              &#39;--basenet=cifar10net&#39;,
                              &#39;--log-interval=50&#39;,
                              &#39;--epochs=3&#39;,
                              &#39;--lr=0.0003&#39;,
                              &#39;--momentum=0.95&#39;,
                              &#39;--batch-size=16&#39;,
                              &#39;--lr-warm-up-epochs=0.1&#39;,
                              &#39;--lr-decay&#39;,
                              &#39;2.0&#39;,
                              &#39;2.5&#39;,
                              &#39;--lr-decay-epochs=0.1&#39;,
                              &#39;--loader-workers=2&#39;,
                              &#39;--output=cifar10_tutorial.pkl&#39;]}
</pre></div>
</div>
<img alt="_images/plugins_cifar10_12_1.png" src="_images/plugins_cifar10_12_1.png" />
<img alt="_images/plugins_cifar10_12_2.png" src="_images/plugins_cifar10_12_2.png" />
<img alt="_images/plugins_cifar10_12_3.png" src="_images/plugins_cifar10_12_3.png" />
<img alt="_images/plugins_cifar10_12_4.png" src="_images/plugins_cifar10_12_4.png" />
<img alt="_images/plugins_cifar10_12_5.png" src="_images/plugins_cifar10_12_5.png" />
<img alt="_images/plugins_cifar10_12_6.png" src="_images/plugins_cifar10_12_6.png" />
<img alt="_images/plugins_cifar10_12_7.png" src="_images/plugins_cifar10_12_7.png" />
<img alt="_images/plugins_cifar10_12_8.png" src="_images/plugins_cifar10_12_8.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cifar10_tutorial.pkl.log: {&#39;message&#39;: None, &#39;levelname&#39;: &#39;INFO&#39;, &#39;name&#39;: &#39;openpifpaf.network.trainer&#39;, &#39;asctime&#39;: &#39;2023-02-01 21:48:27,951&#39;, &#39;type&#39;: &#39;train&#39;, &#39;epoch&#39;: 2, &#39;batch&#39;: 3100, &#39;n_batches&#39;: 3125, &#39;time&#39;: 0.021, &#39;data_time&#39;: 0.002, &#39;lr&#39;: 3e-06, &#39;loss&#39;: -10.63, &#39;head_losses&#39;: [-10.434, -0.196, 0.0]}
</pre></div>
</div>
</div>
</div>
</section>
<section id="prediction">
<h2>Prediction<a class="headerlink" href="#prediction" title="Permalink to this headline">#</a></h2>
<p>First using CLI:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
python -m openpifpaf.predict --checkpoint cifar10_tutorial.pkl.epoch003 images/cifar10_*.png --seed-threshold=0.1 --json-output . --quiet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:openpifpaf.decoder.cifcaf:consistency: decreasing keypoint threshold to seed threshold of 0.100000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span> 
cat cifar10_*.json
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&quot;category_id&quot;: 1, &quot;category&quot;: &quot;plane&quot;, &quot;score&quot;: 0.4, &quot;bbox&quot;: [5.01, 4.96, 21.01, 21.02]}, {&quot;category_id&quot;: 9, &quot;category&quot;: &quot;ship&quot;, &quot;score&quot;: 0.35, &quot;bbox&quot;: [4.97, 5.09, 21.03, 20.95]}, {&quot;category_id&quot;: 3, &quot;category&quot;: &quot;bird&quot;, &quot;score&quot;: 0.329, &quot;bbox&quot;: [4.99, 5.12, 20.99, 20.95]}, {&quot;category_id&quot;: 5, &quot;category&quot;: &quot;deer&quot;, &quot;score&quot;: 0.26, &quot;bbox&quot;: [4.99, 5.01, 20.83, 21.05]}, {&quot;category_id&quot;: 4, &quot;category&quot;: &quot;cat&quot;, &quot;score&quot;: 0.22, &quot;bbox&quot;: [5.11, 5.18, 20.96, 20.98]}, {&quot;category_id&quot;: 6, &quot;category&quot;: &quot;dog&quot;, &quot;score&quot;: 0.217, &quot;bbox&quot;: [4.96, 5.1, 21.07, 20.9]}, {&quot;category_id&quot;: 8, &quot;category&quot;: &quot;horse&quot;, &quot;score&quot;: 0.172, &quot;bbox&quot;: [4.87, 4.95, 21.05, 21.03]}][{&quot;category_id&quot;: 2, &quot;category&quot;: &quot;car&quot;, &quot;score&quot;: 0.484, &quot;bbox&quot;: [5.14, 4.96, 21.01, 21.0]}, {&quot;category_id&quot;: 10, &quot;category&quot;: &quot;truck&quot;, &quot;score&quot;: 0.434, &quot;bbox&quot;: [5.02, 4.88, 21.17, 20.89]}, {&quot;category_id&quot;: 9, &quot;category&quot;: &quot;ship&quot;, &quot;score&quot;: 0.196, &quot;bbox&quot;: [4.99, 4.99, 21.01, 20.86]}][{&quot;category_id&quot;: 9, &quot;category&quot;: &quot;ship&quot;, &quot;score&quot;: 0.392, &quot;bbox&quot;: [4.98, 5.05, 20.97, 20.97]}, {&quot;category_id&quot;: 1, &quot;category&quot;: &quot;plane&quot;, &quot;score&quot;: 0.37, &quot;bbox&quot;: [4.93, 5.05, 21.0, 21.01]}, {&quot;category_id&quot;: 10, &quot;category&quot;: &quot;truck&quot;, &quot;score&quot;: 0.342, &quot;bbox&quot;: [4.97, 5.18, 21.08, 21.07]}, {&quot;category_id&quot;: 2, &quot;category&quot;: &quot;car&quot;, &quot;score&quot;: 0.33, &quot;bbox&quot;: [4.97, 5.01, 21.01, 20.95]}, {&quot;category_id&quot;: 3, &quot;category&quot;: &quot;bird&quot;, &quot;score&quot;: 0.249, &quot;bbox&quot;: [4.99, 5.07, 20.96, 21.03]}, {&quot;category_id&quot;: 5, &quot;category&quot;: &quot;deer&quot;, &quot;score&quot;: 0.167, &quot;bbox&quot;: [4.99, 4.99, 20.97, 21.03]}, {&quot;category_id&quot;: 4, &quot;category&quot;: &quot;cat&quot;, &quot;score&quot;: 0.162, &quot;bbox&quot;: [5.08, 5.07, 20.99, 20.96]}][{&quot;category_id&quot;: 10, &quot;category&quot;: &quot;truck&quot;, &quot;score&quot;: 0.392, &quot;bbox&quot;: [5.15, 4.89, 21.04, 21.03]}, {&quot;category_id&quot;: 2, &quot;category&quot;: &quot;car&quot;, &quot;score&quot;: 0.354, &quot;bbox&quot;: [5.1, 4.96, 21.08, 20.97]}, {&quot;category_id&quot;: 9, &quot;category&quot;: &quot;ship&quot;, &quot;score&quot;: 0.312, &quot;bbox&quot;: [4.96, 4.85, 21.06, 21.03]}, {&quot;category_id&quot;: 1, &quot;category&quot;: &quot;plane&quot;, &quot;score&quot;: 0.302, &quot;bbox&quot;: [4.97, 5.06, 21.03, 21.01]}, {&quot;category_id&quot;: 8, &quot;category&quot;: &quot;horse&quot;, &quot;score&quot;: 0.295, &quot;bbox&quot;: [4.96, 5.0, 21.0, 20.99]}, {&quot;category_id&quot;: 4, &quot;category&quot;: &quot;cat&quot;, &quot;score&quot;: 0.264, &quot;bbox&quot;: [5.04, 5.07, 20.99, 20.98]}, {&quot;category_id&quot;: 3, &quot;category&quot;: &quot;bird&quot;, &quot;score&quot;: 0.237, &quot;bbox&quot;: [4.99, 4.9, 21.06, 21.03]}, {&quot;category_id&quot;: 6, &quot;category&quot;: &quot;dog&quot;, &quot;score&quot;: 0.196, &quot;bbox&quot;: [5.02, 5.03, 20.99, 20.95]}, {&quot;category_id&quot;: 5, &quot;category&quot;: &quot;deer&quot;, &quot;score&quot;: 0.182, &quot;bbox&quot;: [5.04, 4.88, 21.06, 21.09]}, {&quot;category_id&quot;: 7, &quot;category&quot;: &quot;frog&quot;, &quot;score&quot;: 0.159, &quot;bbox&quot;: [5.01, 5.05, 20.98, 20.98]}]
</pre></div>
</div>
</div>
</div>
<p>Using API:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net_cpu</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">openpifpaf</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">Factory</span><span class="p">(</span><span class="n">checkpoint</span><span class="o">=</span><span class="s1">&#39;cifar10_tutorial.pkl.epoch003&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">factory</span><span class="p">()</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">openpifpaf</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">openpifpaf</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">NormalizeAnnotations</span><span class="p">(),</span>
    <span class="n">openpifpaf</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">CenterPadTight</span><span class="p">(</span><span class="mi">16</span><span class="p">),</span>
    <span class="n">openpifpaf</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">EVAL_TRANSFORM</span><span class="p">,</span>
<span class="p">])</span>

<span class="n">openpifpaf</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">CifDetSeeds</span><span class="o">.</span><span class="n">set_threshold</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">decode</span> <span class="o">=</span> <span class="n">openpifpaf</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">factory</span><span class="p">([</span><span class="n">hn</span><span class="o">.</span><span class="n">meta</span> <span class="k">for</span> <span class="n">hn</span> <span class="ow">in</span> <span class="n">net_cpu</span><span class="o">.</span><span class="n">head_nets</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">openpifpaf</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageList</span><span class="p">([</span>
    <span class="s1">&#39;images/cifar10_airplane4.png&#39;</span><span class="p">,</span>
    <span class="s1">&#39;images/cifar10_automobile10.png&#39;</span><span class="p">,</span>
    <span class="s1">&#39;images/cifar10_ship7.png&#39;</span><span class="p">,</span>
    <span class="s1">&#39;images/cifar10_truck8.png&#39;</span><span class="p">,</span>
<span class="p">],</span> <span class="n">preprocess</span><span class="o">=</span><span class="n">preprocess</span><span class="p">)</span>
<span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">meta</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">decode</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">net_cpu</span><span class="p">,</span> <span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> </span><span class="si">{:.0%}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">category</span><span class="p">,</span> <span class="n">pred</span><span class="o">.</span><span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/plugins_cifar10_17_0.png" src="_images/plugins_cifar10_17_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;plane 40%&#39;, &#39;ship 35%&#39;, &#39;bird 33%&#39;]
</pre></div>
</div>
<img alt="_images/plugins_cifar10_17_2.png" src="_images/plugins_cifar10_17_2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;car 48%&#39;, &#39;truck 43%&#39;]
</pre></div>
</div>
<img alt="_images/plugins_cifar10_17_4.png" src="_images/plugins_cifar10_17_4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;ship 39%&#39;, &#39;plane 37%&#39;, &#39;truck 34%&#39;, &#39;car 33%&#39;]
</pre></div>
</div>
<img alt="_images/plugins_cifar10_17_6.png" src="_images/plugins_cifar10_17_6.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;truck 39%&#39;, &#39;car 35%&#39;, &#39;ship 31%&#39;, &#39;plane 30%&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluation">
<h2>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">#</a></h2>
<p>I selected the above images, because their category is clear to me. There are images in cifar10 where it is more difficult to tell what the category is and so it is probably also more difficult for a neural network.</p>
<p>Therefore, we should run a proper quantitative evaluation with <code class="docutils literal notranslate"><span class="pre">openpifpaf.eval</span></code>. It stores its output as a json file, so we print that afterwards.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
python -m openpifpaf.eval --checkpoint cifar10_tutorial.pkl.epoch003 --dataset=cifar10 --seed-threshold=0.1 --instance-threshold=0.1 --quiet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:openpifpaf.decoder.cifcaf:consistency: decreasing keypoint threshold to seed threshold of 0.100000
[INFO] Register count_convNd() for &lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt;.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
python -m json.tool cifar10_tutorial.pkl.epoch003.eval-cifar10.stats.json
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{
    &quot;text_labels&quot;: [
        &quot;total&quot;,
        &quot;plane&quot;,
        &quot;car&quot;,
        &quot;bird&quot;,
        &quot;cat&quot;,
        &quot;deer&quot;,
        &quot;dog&quot;,
        &quot;frog&quot;,
        &quot;horse&quot;,
        &quot;ship&quot;,
        &quot;truck&quot;
    ],
    &quot;stats&quot;: [
        0.4214,
        0.505,
        0.599,
        0.148,
        0.344,
        0.378,
        0.322,
        0.421,
        0.472,
        0.535,
        0.49
    ],
    &quot;args&quot;: [
        &quot;/opt/hostedtoolcache/Python/3.8.16/x64/lib/python3.8/site-packages/openpifpaf/eval.py&quot;,
        &quot;--checkpoint&quot;,
        &quot;cifar10_tutorial.pkl.epoch003&quot;,
        &quot;--dataset=cifar10&quot;,
        &quot;--seed-threshold=0.1&quot;,
        &quot;--instance-threshold=0.1&quot;,
        &quot;--quiet&quot;
    ],
    &quot;version&quot;: &quot;0.14.0+16.g5be8d6e&quot;,
    &quot;dataset&quot;: &quot;cifar10&quot;,
    &quot;total_time&quot;: 29.035804658000075,
    &quot;checkpoint&quot;: &quot;cifar10_tutorial.pkl.epoch003&quot;,
    &quot;count_ops&quot;: [
        421736880.0,
        105180.0
    ],
    &quot;file_size&quot;: 436615,
    &quot;n_images&quot;: 10000,
    &quot;decoder_time&quot;: 6.709794749005141,
    &quot;nn_time&quot;: 12.318138588003421
}
</pre></div>
</div>
</div>
</div>
<p>We see that some categories like “plane”, “car” and “ship” are learned quickly whereas as others are learned poorly (e.g. “bird”). The poor performance is not surprising as we trained our network for a few epochs only.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="tutorial_opencv.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">OpenCV</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="moduledocs.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modules</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By <a href="https://www.epfl.ch/labs/vita/">EPFL VITA</a> and <a href="https://github.com/vita-epfl/openpifpaf/graphs/contributors">contributors</a>.<br/>
  
      &copy; Copyright 2020-2022.<br/>
    <div class="extra_footer">
      <p>Powered by <a href="https://jupyterbook.org/">Jupyter Book</a>.</p>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>